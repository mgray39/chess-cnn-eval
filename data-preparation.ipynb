{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "25aa10eb-c98d-4fbc-b987-12afe717190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "if __name__ =='__main__':\n",
    "    if not os.path.exists('./prepared_data/'):\n",
    "        os.mkdir('./prepared_data/')\n",
    "        \n",
    "    df = pd.read_csv('./data/chessData.csv')\n",
    "    \n",
    "    train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "\n",
    "    train_df.to_csv('./prepared_data/train_chess_data.csv', encoding = 'utf-8', index=False)\n",
    "    test_df.to_csv('./prepared_data/test_chess_data.csv', encoding = 'utf-8', index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96fbdcc7-b315-4768-8e53-f95a77cbeaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import chess\n",
    "import torch\n",
    "\n",
    "\n",
    "piece_list = ['pawn','knight','bishop','rook','queen','king']\n",
    "piece_key = range(1,7)\n",
    "\n",
    "piece_dict = dict(zip(piece_list, piece_key))\n",
    "\n",
    "colour_dict = {'black':0, 'white':1}\n",
    "\n",
    "\n",
    "def fen_translator(fen_string: str):\n",
    "    \n",
    "    board = chess.Board(fen_string)\n",
    "    \n",
    "    tensor = board_to_tensor(board = board)\n",
    "    \n",
    "    return tensor\n",
    "\n",
    "\n",
    "def board_to_tensor(board: chess.Board) -> torch.Tensor:\n",
    "    \n",
    "    array_list = []\n",
    "    \n",
    "    for colour in colour_dict.values():\n",
    "        for piece in piece_dict.values():\n",
    "            piece_array = np.reshape(np.array(str(board.pieces(piece, colour)).replace(' ', ',').replace('.','0').replace('\\n', ',').split(',')), (8,8)).astype(int)\n",
    "            array_list.append(piece_array)\n",
    "    \n",
    "    \n",
    "    array_list.append(create_ep_tensor(board))\n",
    "    array_list.append(create_castle_tensor(board))\n",
    "    array_list.append(create_half_move_clock_draw_tensor(board))\n",
    "    array_list.append(create_to_move_tensor(board))\n",
    "    \n",
    "    tensor = torch.tensor(np.array(array_list))\n",
    "    \n",
    "    return tensor\n",
    "\n",
    "\n",
    "def create_ep_tensor(board: chess.Board) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Expects a board object and returns an 8x8 array with 1 on any ep position. \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    ep_tensor = np.zeros(64)\n",
    "    \n",
    "    if board.ep_square:\n",
    "        ep = board.ep_square\n",
    "        ep_tensor[ep] = 1\n",
    "        \n",
    "    ep_tensor = ep_tensor.reshape(8,8)[-1::-1]\n",
    "    \n",
    "    return ep_tensor\n",
    "\n",
    "\n",
    "def create_castle_tensor(board: chess.Board) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Expects a board object and returns a 8x8 array with 1s in the corners where the kings may castle\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    castle_tensor = np.zeros(64).reshape((8,8))\n",
    "    \n",
    "    castling_rights = board.castling_rights\n",
    "    \n",
    "    pos_dict = {63: (0,7),\n",
    "                56: (0,0),\n",
    "                7: (7,7),\n",
    "                0: (7,0)}\n",
    "    \n",
    "    for pos_number, pos_coordinates in pos_dict.items():\n",
    "        \n",
    "        if castling_rights >= 2**pos_number:\n",
    "            castling_rights -= 2**pos_number\n",
    "            castle_tensor[pos_coordinates] = 1\n",
    "        \n",
    "    return castle_tensor\n",
    "\n",
    "\n",
    "def create_half_move_clock_draw_tensor(board: chess.Board) -> np.ndarray:\n",
    "    \n",
    "    if board.halfmove_clock>=100:\n",
    "        \n",
    "        return np.ones(64).reshape((8,8))\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return np.zeros(64).reshape((8,8))\n",
    "    \n",
    "    \n",
    "def create_to_move_tensor(board: chess.Board) -> np.ndarray:\n",
    "    \n",
    "    if board.turn:\n",
    "        return np.hstack((np.zeros(32), np.ones(32))).reshape(8,8)\n",
    "    \n",
    "    else:\n",
    "        return np.hstack((np.ones(32), np.zeros(32))).reshape(8,8)\n",
    "    \n",
    "    \n",
    "def evaluation_mate_handler(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    df = (df\n",
    "          .dropna()\n",
    "          .assign(Evaluation = lambda df: (df['Evaluation']\n",
    "                                            .mask(df['Evaluation']\n",
    "                                                  .str.contains('#-'), '-20000')))\n",
    "          .assign(Evaluation = lambda df: (df['Evaluation']\n",
    "                                            .mask(df['Evaluation']\n",
    "                                                  .str.contains('#+'), '20000')))\n",
    "          .assign(Evaluation = lambda df: (df['Evaluation']\n",
    "                                           .str.replace('\\ufeff', '')\n",
    "                                           .str.replace(r'\\s', '', regex=True)\n",
    "                                           .str.replace('+', '')\n",
    "                                           .astype(int))\n",
    "                 )\n",
    "         )\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10314767-9e43-4042-8fc9-990bad2c3f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_path = './data/chessData.csv'\n",
    "\n",
    "df = pd.read_csv(chess_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f6134179-18ec-4e98-b1fd-f4d2b91e6d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20000)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hold_batch[1].abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "320c7124-7e8f-4e5d-a527-37aae5f1dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def div_max(tensor: torch.Tensor) -> torch.Tensor:\n",
    "    \n",
    "    tensor = tensor.to(torch.float32)\n",
    "    \n",
    "    tensor /= tensor.abs().max()\n",
    "    \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "07fa8d6e-15bb-4a10-801d-a4df4a48bfb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-20000'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duck = '20000'\n",
    "\n",
    "'-'+duck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f47659-ddd0-4974-98fe-f555884a0695",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a1313cfe-d744-4f57-b9f8-5202aad7687f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_max(hold_batch[1].to(torch.float32)).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb8aea79-b11a-47aa-9837-c821d5e5d233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_79883/471159207.py:118: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  .str.replace('+', '')\n"
     ]
    }
   ],
   "source": [
    "df = df.pipe(evaluation_mate_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e20a865a-8092-45a5-95f6-530c576cab38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.query('-1000000<Evaluation<1000000')['Evaluation'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63aa1d1d-2103-4af8-ad97-c919f1b1d205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Evaluation'].hist(bins = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae69b91-a002-4cfe-aa27-88f9c139bfba",
   "metadata": {},
   "source": [
    "## Building the Pytorch Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9cb696e-46e3-4831-b632-715dd7520ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "912642c5-46fb-492b-b85f-9b7e20346139",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FENDataset(Dataset):\n",
    "\n",
    "    def __init__(self, evaluation_file_path: str):\n",
    "        self.evaluation_file_path = evaluation_file_path\n",
    "        self.evaluation_data = (pd.read_csv(self.evaluation_file_path)\n",
    "                                .pipe(evaluation_mate_handler))\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.evaluation_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label = self.evaluation_data.loc[idx, 'Evaluation']\n",
    "        tensor = fen_translator(self.evaluation_data.loc[idx, 'FEN'])\n",
    "        \n",
    "        return tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d7e47c5-9fb6-4de0-a1fa-4d6897e1071b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_282123/3894474985.py:118: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  .str.replace('+', '')\n",
      "/tmp/ipykernel_282123/3894474985.py:118: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  .str.replace('+', '')\n"
     ]
    }
   ],
   "source": [
    "train_dataset = FENDataset( './prepared_data/train_chess_data.csv')\n",
    "test_dataset = FENDataset( './prepared_data/test_chess_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a950fd23-e51e-4807-aaf5-6d2da87c596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 64, shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8b4c60cd-675d-4638-b3d1-0dcd3c997383",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "hold_batch = None\n",
    "i = 0\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    if i ==38: \n",
    "        hold_batch = batch\n",
    "        break\n",
    "    else:\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e8e0aeb9-0c60-4a6d-8f4a-9942b9b746f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e25d25ef-9a11-4c1c-90ae-376cbc7173d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8285698., grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(net(hold_batch[0].to(torch.float32)), hold_batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5edbe694-91ec-4a27-be6e-6396bf1298e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8285697., grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(net(hold_batch[0].to(torch.float32)).reshape(-1), hold_batch[1].to(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c981d205-06e9-462b-8170-94b2a81ed85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([86.8813, 86.8813, 86.8813, 86.8813, 86.8813, 86.8813, 86.8813, 86.8813,\n",
       "        86.8813, 86.8813, 86.8813, 86.8813, 86.8813, 86.8813, 86.8813, 86.8813,\n",
       "        86.8813, 86.8813, 86.8813, 86.8813, 86.8813, 86.8813, 86.8813, 86.8813,\n",
       "        86.8813, 86.8813, 86.8813, 86.8813, 86.8813, 86.8813, 86.8813, 86.8813,\n",
       "        86.8813, 86.8813, 86.8813, 86.8813, 86.8813, 86.8813, 86.8813, 86.8813,\n",
       "        86.8813, 86.8813, 86.8813, 86.8813, 86.8813, 86.8813, 86.8813, 86.8813,\n",
       "        86.8813, 86.8813, 86.8813, 86.8813, 86.8813, 86.8813, 86.8813, 86.8813,\n",
       "        86.8813, 86.8813, 86.8813, 86.8813, 86.8813, 86.8813, 86.8813, 86.8813],\n",
       "       grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(hold_batch[0].to(torch.float32)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fd1cab7b-c482-4ece-9ff4-098c1c909c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -5814, -20000,    178,    983,    -50,      0,    229,    119,      0,\n",
       "            32,    376,    316,   -885,     72,   -138,     26,    -94,     71,\n",
       "             0,   -165,     59,    324,     13,     21,    279,     16,   -110,\n",
       "            13,   -530,    -84,    102,    109,     52,  -6923,   -903,     21,\n",
       "          -281,     53,    237,    200,      0,    -52,   -243,     83,    -56,\n",
       "            57,   -132,    123,      0,    174,     53,    667,   -118,  -6047,\n",
       "          -272,     70,   -162,     59,   -615,    111,     97,    -84,    -92,\n",
       "           292])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hold_batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cd83f703-ed53-4fa3-a74b-668002d96107",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813],\n",
       "        [86.8813]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(hold_batch[0].to(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089844f3-f122-4db3-afad-3724b7b210b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bed8cf5-9e36-434b-b3d6-92ca0c8cc5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09e6e618-aa42-4fc2-8d46-427f14c92c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmtstr = \"%(asctime)s: (%(filename)s): %(levelname)s: %(funcName)s Line: %(lineno)d - %(message)s\"\n",
    "datestr = \"%Y-%m-%d %H:%M:%S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a1dab3b-61ca-44c5-a916-d3570f253ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "        filename=\"custom_log_output.log\",\n",
    "        level=logging.DEBUG,\n",
    "        filemode=\"w\",\n",
    "        format=fmtstr,\n",
    "        datefmt=datestr,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32a5ddbc-e86a-43ad-8655-065a53ff78cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('this is a log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66f88ad2-1c8b-4b27-9142-d89db461b09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.448298\n"
     ]
    }
   ],
   "source": [
    "print(f'{0.448298382392939283839283:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89d762c4-1735-4af1-9484-69399652b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3c362cc-32d4-4352-b8ac-f05db4d4f083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22929272649999977"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= np.array([2.546,3.489,7.4869,11.4698])\n",
    "b= np.array([2.1546,3.4489,7.74869,11.54698])\n",
    "\n",
    "np.sum((a-b)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dd4e5fa-a8b0-4681-a417-42169abc3ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from data_load_utils import FENDataset\n",
    "from torchvision import transforms\n",
    "import argparse\n",
    "from torch.utils.data import DataLoader\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "from torch.optim import AdamW\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e8b0b86-640b-452b-90b6-33a594af3848",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, number_of_convolutions, number_of_filters): \n",
    "        super().__init__() \n",
    "        self.number_of_convolutions = number_of_convolutions\n",
    "        self.number_of_filters = number_of_filters\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(16, number_of_filters, kernel_size=3, stride = 1, padding = 'same') # Input Channels, Number of Kernels, Kernel Size \n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 1, padding = 1) # Kernel Size, Stride \n",
    "        \n",
    "        self.residual_list = nn.ModuleList([nn.Conv2d(number_of_filters, number_of_filters, kernel_size=3, stride = 1, padding='same') for i in range(number_of_convolutions)])\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(number_of_filters*(8+number_of_convolutions+1)**2, 1) \n",
    "    \n",
    "    def forward(self, x): \n",
    "        \n",
    "        x = self.pool(F.relu(self.conv1(x))) \n",
    "        \n",
    "        for conv_layer in self.residual_list:\n",
    "            x = self.pool(F.relu(conv_layer(x))) \n",
    "        \n",
    "        x = torch.flatten(x, 0) \n",
    "        \n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f61c6f50-f44b-4a38-b1aa-73ecaaf1158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from data_load_utils import FENDataset\n",
    "from torchvision import transforms\n",
    "import argparse\n",
    "from torch.utils.data import DataLoader\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "from torch.optim import AdamW\n",
    "import numpy as np\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, number_of_convolutions, number_of_filters): \n",
    "        super().__init__() \n",
    "        self.number_of_convolutions = number_of_convolutions\n",
    "        self.number_of_filters = number_of_filters\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(16, number_of_filters, kernel_size=3, stride = 1, padding = 'same') # Input Channels, Number of Kernels, Kernel Size \n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 1, padding = 1) # Kernel Size, Stride \n",
    "        \n",
    "        self.residual_list = nn.ModuleList([nn.Conv2d(number_of_filters, number_of_filters, kernel_size=3, stride = 1, padding='same') for i in range(number_of_convolutions)])\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(number_of_filters*(8+number_of_convolutions+1)**2, 1) \n",
    "    \n",
    "    def forward(self, x): \n",
    "        \n",
    "        x = self.pool(F.relu(self.conv1(x))) \n",
    "        \n",
    "        for conv_layer in self.residual_list:\n",
    "            x = self.pool(F.relu(conv_layer(x))) \n",
    "        \n",
    "        x = torch.flatten(x, 1)#1 because passing batch? \n",
    "        \n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4610d586-3d26-45cd-a91b-295ff4f56098",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Model(number_of_convolutions=5, number_of_filters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2360f545-4089-49ff-88c2-63b6eb35434a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('models/chess_nc_5_nf_10_e_2_bs_64_lr_0.001.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16db50c5-b931-4c3e-8206-a35152f7aab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEN</th>\n",
       "      <th>Evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR ...</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rnbqkbnr/pppp1ppp/4p3/8/4P3/8/PPPP1PPP/RNBQKBN...</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rnbqkbnr/pppp1ppp/4p3/8/3PP3/8/PPP2PPP/RNBQKBN...</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rnbqkbnr/ppp2ppp/4p3/3p4/3PP3/8/PPP2PPP/RNBQKB...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rnbqkbnr/ppp2ppp/4p3/3p4/3PP3/8/PPPN1PPP/R1BQK...</td>\n",
       "      <td>-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12958030</th>\n",
       "      <td>r1bqkb1r/pp3ppp/1nn1p3/3pP3/3P1P2/1B3N2/PP2Q1P...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12958031</th>\n",
       "      <td>r2qkb1r/pp1b1ppp/1nn1p3/3pP3/3P1P2/1B3N2/PP2Q1...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12958032</th>\n",
       "      <td>r2qkb1r/pp1b1ppp/1nn1p3/3pP3/3P1P2/1BN2N2/PP2Q...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12958033</th>\n",
       "      <td>r2qkb1r/pp1b1ppp/1n2p3/n2pP3/3P1P2/1BN2N2/PP2Q...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12958034</th>\n",
       "      <td>r2qkb1r/pp1b1ppp/1n2p3/n2pP3/3P1P2/2N2N2/PPB1Q...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12958035 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        FEN  Evaluation\n",
       "0         rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR ...         -10\n",
       "1         rnbqkbnr/pppp1ppp/4p3/8/4P3/8/PPPP1PPP/RNBQKBN...          56\n",
       "2         rnbqkbnr/pppp1ppp/4p3/8/3PP3/8/PPP2PPP/RNBQKBN...          -9\n",
       "3         rnbqkbnr/ppp2ppp/4p3/3p4/3PP3/8/PPP2PPP/RNBQKB...          52\n",
       "4         rnbqkbnr/ppp2ppp/4p3/3p4/3PP3/8/PPPN1PPP/R1BQK...         -26\n",
       "...                                                     ...         ...\n",
       "12958030  r1bqkb1r/pp3ppp/1nn1p3/3pP3/3P1P2/1B3N2/PP2Q1P...           6\n",
       "12958031  r2qkb1r/pp1b1ppp/1nn1p3/3pP3/3P1P2/1B3N2/PP2Q1...          84\n",
       "12958032  r2qkb1r/pp1b1ppp/1nn1p3/3pP3/3P1P2/1BN2N2/PP2Q...           0\n",
       "12958033  r2qkb1r/pp1b1ppp/1n2p3/n2pP3/3P1P2/1BN2N2/PP2Q...         115\n",
       "12958034  r2qkb1r/pp1b1ppp/1n2p3/n2pP3/3P1P2/2N2N2/PPB1Q...          45\n",
       "\n",
       "[12958035 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab583072-dc9a-49a1-82fa-132b5f93c3fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m frame \u001b[38;5;241m=\u001b[39m fen_translator(\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFEN\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "frame = fen_translator(df.loc[0,'FEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6c98655-8694-47a6-a8b5-6e0a995e76a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_79883/2816279505.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(frame)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0.,  ..., 0., 1., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 1.,  ..., 1., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 1.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f063b3c2-a810-4b14-9f1f-8f539484b6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0.,  ..., 0., 1., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 1.,  ..., 1., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 1.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "991d0e45-ea4a-4dd0-983b-550e99994a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_79883/2085428302.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  net(torch.tensor(frame).to(torch.float32))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (10x196 and 1960x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(conv_layer(x))) \n\u001b[1;32m     35\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;66;03m#1 because passing batch? \u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (10x196 and 1960x1)"
     ]
    }
   ],
   "source": [
    "\n",
    "net(torch.tensor(frame).to(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36442a2b-b8e1-4104-a72e-64b2873b037f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (10x196 and 1960x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(conv_layer(x))) \n\u001b[1;32m     35\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;66;03m#1 because passing batch? \u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (10x196 and 1960x1)"
     ]
    }
   ],
   "source": [
    "net(frame.to(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1ab334ec-9ce7-493e-a3d1-12038e32f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,\n",
    "                     padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        print(identity.shape)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        print(out.shape)\n",
    "        out = self.bn1(out)\n",
    "        print(out.shape)\n",
    "        out = self.relu(out)\n",
    "        print(out.shape)\n",
    "        out = self.conv2(out)\n",
    "        print(out.shape)\n",
    "        out = self.bn2(out)\n",
    "        print(out.shape)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fdc26d21-bc7a-4ff6-ba21-76e110c74de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetModel(nn.Module):\n",
    "    def __init__(self, number_of_convolutions, number_of_filters): \n",
    "        super().__init__() \n",
    "        self.number_of_convolutions = number_of_convolutions\n",
    "        self.number_of_filters = number_of_filters\n",
    "        \n",
    "        self.basicblock =  BasicBlock(16, number_of_filters)\n",
    "        \n",
    "        \n",
    "        self.block_list = nn.ModuleList([BasicBlock(number_of_filters, number_of_filters) for i in range(number_of_convolutions)])\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(16*8*8, 1) \n",
    "    \n",
    "    def forward(self, x): \n",
    "        \n",
    "        x = self.basicblock(x)\n",
    "        print(x.shape)\n",
    "        \n",
    "        for block_layer in self.block_list:\n",
    "            x = block_layer(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)#1 because passing batch? \n",
    "        \n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "156f3b57-6748-44e2-822c-dc51341dccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4b2219ed-d055-469a-8814-e68bcd54bd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = BasicBlock(16,16).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d225b463-3975-4ad6-86dd-ca16c4135b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = ResnetModel(5,16).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f8f0012-c3dc-49fa-9a1b-fc820a15275a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16*8*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86d15412-6421-4c64-813f-a819e12218fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 16, 8, 8])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hold_batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68d8a6ac-aecc-4623-8e14-8af928810fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1             [-1, 16, 8, 8]           2,304\n",
      "       BatchNorm2d-2             [-1, 16, 8, 8]              32\n",
      "              ReLU-3             [-1, 16, 8, 8]               0\n",
      "            Conv2d-4             [-1, 16, 8, 8]           2,304\n",
      "       BatchNorm2d-5             [-1, 16, 8, 8]              32\n",
      "              ReLU-6             [-1, 16, 8, 8]               0\n",
      "================================================================\n",
      "Total params: 4,672\n",
      "Trainable params: 4,672\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.05\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.07\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(block, input_size=(16, 8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3602d943-9ddb-4c08-8d0f-5ec6235cf5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([2, 16, 8, 8])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1             [-1, 16, 8, 8]           2,304\n",
      "       BatchNorm2d-2             [-1, 16, 8, 8]              32\n",
      "              ReLU-3             [-1, 16, 8, 8]               0\n",
      "            Conv2d-4             [-1, 16, 8, 8]           2,304\n",
      "       BatchNorm2d-5             [-1, 16, 8, 8]              32\n",
      "              ReLU-6             [-1, 16, 8, 8]               0\n",
      "        BasicBlock-7             [-1, 16, 8, 8]               0\n",
      "            Conv2d-8             [-1, 16, 8, 8]           2,304\n",
      "       BatchNorm2d-9             [-1, 16, 8, 8]              32\n",
      "             ReLU-10             [-1, 16, 8, 8]               0\n",
      "           Conv2d-11             [-1, 16, 8, 8]           2,304\n",
      "      BatchNorm2d-12             [-1, 16, 8, 8]              32\n",
      "             ReLU-13             [-1, 16, 8, 8]               0\n",
      "       BasicBlock-14             [-1, 16, 8, 8]               0\n",
      "           Conv2d-15             [-1, 16, 8, 8]           2,304\n",
      "      BatchNorm2d-16             [-1, 16, 8, 8]              32\n",
      "             ReLU-17             [-1, 16, 8, 8]               0\n",
      "           Conv2d-18             [-1, 16, 8, 8]           2,304\n",
      "      BatchNorm2d-19             [-1, 16, 8, 8]              32\n",
      "             ReLU-20             [-1, 16, 8, 8]               0\n",
      "       BasicBlock-21             [-1, 16, 8, 8]               0\n",
      "           Conv2d-22             [-1, 16, 8, 8]           2,304\n",
      "      BatchNorm2d-23             [-1, 16, 8, 8]              32\n",
      "             ReLU-24             [-1, 16, 8, 8]               0\n",
      "           Conv2d-25             [-1, 16, 8, 8]           2,304\n",
      "      BatchNorm2d-26             [-1, 16, 8, 8]              32\n",
      "             ReLU-27             [-1, 16, 8, 8]               0\n",
      "       BasicBlock-28             [-1, 16, 8, 8]               0\n",
      "           Conv2d-29             [-1, 16, 8, 8]           2,304\n",
      "      BatchNorm2d-30             [-1, 16, 8, 8]              32\n",
      "             ReLU-31             [-1, 16, 8, 8]               0\n",
      "           Conv2d-32             [-1, 16, 8, 8]           2,304\n",
      "      BatchNorm2d-33             [-1, 16, 8, 8]              32\n",
      "             ReLU-34             [-1, 16, 8, 8]               0\n",
      "       BasicBlock-35             [-1, 16, 8, 8]               0\n",
      "           Conv2d-36             [-1, 16, 8, 8]           2,304\n",
      "      BatchNorm2d-37             [-1, 16, 8, 8]              32\n",
      "             ReLU-38             [-1, 16, 8, 8]               0\n",
      "           Conv2d-39             [-1, 16, 8, 8]           2,304\n",
      "      BatchNorm2d-40             [-1, 16, 8, 8]              32\n",
      "             ReLU-41             [-1, 16, 8, 8]               0\n",
      "       BasicBlock-42             [-1, 16, 8, 8]               0\n",
      "           Linear-43                    [-1, 1]           1,025\n",
      "================================================================\n",
      "Total params: 29,057\n",
      "Trainable params: 29,057\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.33\n",
      "Params size (MB): 0.11\n",
      "Estimated Total Size (MB): 0.44\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(resnet_model, input_size=(16, 8, 8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "866f3848-09ee-4604-a8b8-d59bc03d6df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n",
      "torch.Size([64, 16, 8, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7736],\n",
       "        [ 1.0469],\n",
       "        [ 1.8279],\n",
       "        [ 2.0453],\n",
       "        [ 0.4074],\n",
       "        [ 1.2706],\n",
       "        [ 0.7688],\n",
       "        [ 0.8457],\n",
       "        [ 1.5446],\n",
       "        [ 3.0530],\n",
       "        [ 1.2010],\n",
       "        [ 1.2852],\n",
       "        [ 0.6718],\n",
       "        [ 1.4506],\n",
       "        [ 0.9064],\n",
       "        [ 0.7543],\n",
       "        [ 1.9375],\n",
       "        [ 1.8682],\n",
       "        [ 0.1956],\n",
       "        [ 0.0975],\n",
       "        [-0.3941],\n",
       "        [-0.2912],\n",
       "        [ 1.8353],\n",
       "        [ 1.5088],\n",
       "        [ 1.1772],\n",
       "        [-1.4295],\n",
       "        [ 0.5783],\n",
       "        [ 0.7171],\n",
       "        [ 0.2927],\n",
       "        [ 1.7166],\n",
       "        [ 1.7888],\n",
       "        [ 1.4183],\n",
       "        [-0.1855],\n",
       "        [ 1.7660],\n",
       "        [ 0.7692],\n",
       "        [ 1.1087],\n",
       "        [ 2.3195],\n",
       "        [-0.1153],\n",
       "        [ 1.4937],\n",
       "        [ 1.8711],\n",
       "        [ 0.7237],\n",
       "        [ 0.4986],\n",
       "        [ 0.7086],\n",
       "        [ 1.5196],\n",
       "        [ 1.2619],\n",
       "        [ 1.2157],\n",
       "        [ 1.8182],\n",
       "        [ 1.4682],\n",
       "        [ 0.8748],\n",
       "        [ 1.5197],\n",
       "        [ 1.7775],\n",
       "        [ 0.8799],\n",
       "        [ 0.1574],\n",
       "        [ 1.4024],\n",
       "        [ 1.0376],\n",
       "        [ 0.9351],\n",
       "        [ 2.2581],\n",
       "        [ 0.8776],\n",
       "        [ 1.8843],\n",
       "        [ 0.2084],\n",
       "        [ 0.1415],\n",
       "        [ 0.2215],\n",
       "        [ 1.8637],\n",
       "        [ 1.0562]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_model(hold_batch[0].to(torch.float).to('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8390e7a-176f-4619-b874-85c9d5c4f1af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
